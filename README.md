# ‚òÅÔ∏è Dados Clim√°ticos com Apache Airflow

Este projeto utiliza Apache Airflow para automatizar a extra√ß√£o de dados clim√°ticos da API do Visual Crossing e salv√°-los em arquivos CSV. O DAG √© configurado para rodar semanalmente, buscando dados para um per√≠odo de 7 dias.

## üìã Pr√©-requisitos

Para rodar este DAG, voc√™ precisar√° ter instalado e configurado o seguinte ambiente:

* **Apache Airflow:** A plataforma utilizada para orquestrar o fluxo de trabalho.
* **Python 3.x:** A linguagem de programa√ß√£o na qual o DAG foi escrito.
* **Bibliotecas Python:** As depend√™ncias do projeto, especificadas no arquivo `dados_climaticos.py`. As principais s√£o:
    * `pendulum`
    * `apache-airflow`
    * `pandas`
    * `requests`
* **Chave de API do Visual Crossing:** Voc√™ precisar√° obter uma chave de API gratuita ou paga no site do Visual Crossing ([https://www.visualcrossing.com/](https://www.visualcrossing.com/)) para acessar os dados clim√°ticos.

## ‚öôÔ∏è Instala√ß√£o e Configura√ß√£o

1. **Clone o reposit√≥rio:**
   ```bash
   git clone https://github.com/vitaless7/pipeline_dados_climaticos.git
   cd pipeline_dados_climaticos

2.  **Instale as depend√™ncias do Python:** Navegue at√© o diret√≥rio do projeto e instale as bibliotecas necess√°rias. √â altamente recomend√°vel usar um ambiente virtual (`venv` ou `conda`).

    ```bash
    pip install pendulum apache-airflow pandas requests
    ```

    *(Note: `apache-airflow` pode exigir depend√™ncias adicionais dependendo da sua configura√ß√£o. Consulte a documenta√ß√£o oficial do Airflow para mais detalhes.)*

3.  **Configure o Airflow:**

    * Copie o arquivo `dados_climaticos.py` para o diret√≥rio `dags` configurado no seu ambiente Airflow.

4.  **Configure a Chave de API do Visual Crossing:**

    * Abra o arquivo `dados_climaticos.py`.
    * Localize a linha que define a vari√°vel `key` dentro da fun√ß√£o `extrai_dados`.
    * Substitua o valor placeholder pela sua chave de API do Visual Crossing.

    ```python
    key = 'SUA_CHAVE_AQUI' # Substitua SUA_CHAVE_AQUI pela sua chave real
    ```

    * **Alternativa (Recomendado para produ√ß√£o):** Considere armazenar sua chave de API como uma Connection ou Variable no Airflow para maior seguran√ßa, em vez de deix√°-la diretamente no c√≥digo do DAG.

## ‚ñ∂Ô∏è Como Rodar

Este DAG √© gerenciado e executado pelo Apache Airflow.

1.  **Inicie o Airflow:** Inicie o webserver e o scheduler do Airflow.

    ```bash
    airflow webserver -p 8080
    airflow scheduler
    ```

    *(O comando para iniciar pode variar dependendo da sua instala√ß√£o do Airflow.)*

2.  **Acesse a UI do Airflow:** Abra seu navegador e acesse a interface web do Airflow (geralmente em `http://localhost:8080`).

3.  **Encontre o DAG:** Na lista de DAGs, procure por `dados_climaticos`.

4.  **Habilite o DAG:** Clique no bot√£o de toggle para habilitar o DAG.

5.  **Execu√ß√£o Autom√°tica:** O DAG est√° configurado com um `schedule_interval='0 0 * * 1'`, o que significa que ele ser√° executado automaticamente toda segunda-feira √† meia-noite (UTC, conforme definido no `start_date`).

6.  **Execu√ß√£o Manual (Opcional):** Voc√™ pode acionar o DAG manualmente clicando no bot√£o "Trigger DAG" na UI do Airflow. Ao acionar manualmente, o Airflow utilizar√° a `start_date` e o `data_interval_end` para determinar o per√≠odo de execu√ß√£o.

## üìÅ Estrutura de Arquivos de Sa√≠da

O DAG criar√° pastas e salvar√° os arquivos CSV no seguinte formato:
 1. ‚îî‚îÄ‚îÄ semana=YYYY-MM-DD/
 2. ‚îú‚îÄ‚îÄ dados_brutos.csv
 3. ‚îú‚îÄ‚îÄ temperaturas.csv
 4. ‚îî‚îÄ‚îÄ condicoes.csv<br>
Onde `YYYY-MM-DD` representa a data de in√≠cio do intervalo de 7 dias para o qual os dados foram extra√≠dos (correspondente ao `data_interval_end` da execu√ß√£o do DAG).

* `dados_brutos.csv`: Cont√©m todos os dados retornados pela API do Visual Crossing para o per√≠odo.
* `temperaturas.csv`: Cont√©m as colunas `datetime`, `tempmin`, `temp` e `tempmax`.
* `condicoes.csv`: Cont√©m as colunas `datetime`, `description` e `icon`.

## ‚ö†Ô∏è Poss√≠veis Problemas e Solu√ß√µes

* **Erro na Chave de API:** Verifique se a chave de API no arquivo `dados_climaticos.py` (ou na Connection/Variable do Airflow) est√° correta.
* **Problemas de Permiss√£o:** Certifique-se de que o usu√°rio que executa o worker do Airflow tenha permiss√£o para criar diret√≥rios e arquivos no caminho especificado (`/home/vitaless/Documentos/airflowalura/`).
* **Falha na Conex√£o com a API:** Verifique sua conex√£o com a internet e se o servi√ßo do Visual Crossing est√° dispon√≠vel. A fun√ß√£o `extrai_dados` inclui tratamento de erro b√°sico para falhas na requisi√ß√£o.
* **Formato de Data:** O DAG utiliza `data_interval_end` fornecido pelo Airflow. A fun√ß√£o `extrai_dados` tenta converter esta string para um objeto `datetime`. Erros de formato podem ocorrer se o Airflow ou a configura√ß√£o de data/hora do sistema n√£o estiverem corretos.
* **`ModuleNotFoundError`:** Certifique-se de que todas as bibliotecas Python necess√°rias foram instaladas no ambiente onde o Airflow worker est√° sendo executado.

---

